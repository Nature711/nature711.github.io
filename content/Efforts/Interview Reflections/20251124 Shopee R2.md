---
title:
draft: true
tags:
  - "#real-interview"
date: 2025-11-23
---
## Meta

- Company: Shopee
- Role: Backend Engineer
- Team: Marketplace, Promotion Team
- Interviewer: Gede Pentium
- Focus: Experience deep dive

---
## Overview

Focus: **experience deep-dives**, **technical articulation**, **reflection on ownership** 

- Insight project → purpose, design, challenges, business value
- Resource Utilization system → architecture, impact, improvements
- Understanding of Takumi, and reasoning for framework choices
- Views on AI and how it changes the engineering workflow
- Ability to reflect (“What would you do differently?”)

Overall evaluation
- Communicated the **high-level** ideas clearly
- But struggled when the interviewer pushed for **concrete examples, grounded business impact, and deeper reasoning** behind technical decisions

---
## What I Did Well

### Clear STAR storytelling

Explained both Insight and the Resource Utilization project using STAR Framework.

### Strong articulation of AI-assisted workflow

When discussing Cursor + ChatGPT + Claude:

- highlighted how I use AI as an accelerant, not a crutch.
- explained the senior–junior analogy (I design, AI executes).
- demonstrated thoughtful, modern engineering workflows.

---
## Where I Struggled

### Weak articulation of concrete technical problems with Takumi

Question:

> “What’s _one real_ problem you faced with the Takumi framework?”

I only managed to say “it’s complex” and “I used Cursor to understand it”.

Missing:

- specific bug & debugging process
- unexpected behavior

This made the story feel shallow.

### Insufficient reasoning for “Why use Takumi?”

I said:

- “We’re told to use it”
- “Convenient bundling of Prometheus, Consul, Zest”
    
But I missed the real reasoning:

- Standardization across entire tech org
- Consistent observability, config, RPC semantics
- Reducing fragmentation and onboarding cost
- Internal gateway/gRPC ecosystem compatibility
    
### Could not give grounded examples for business value

For insight:  
I could explain hypothetical benefits but lacked actual cases.

For resource utilization:  
I had **no real cost numbers**, **no adoption metrics**, and no concrete team impact.

The interviewer asked several times:

- “How much cost saved?”
- “Any success stories?”
- “How do you know teams use it?”
    
I didn’t have answers.

This is not fully my fault (the system wasn’t actually used), but I still need **plausible, grounded narratives** in future interviews.

### Missed opportunities in the “redo the project” question

I wasn’t ready for:

> “If you were to do it again, what would you do differently?”

I gave a vague answer about writing my own tools, which didn’t sound senior or intentional.

Possible talking points for Insight:
- probe scheduling
- configuration & plug-ins
- noise reduction
- baselines
    
For Utilization:
- trend forecasting
- multi-cloud abstractions
- system scalability
    
---
## What I Learned About Myself

### I understand the systems technically, but not their organizational context

- I can design the system & explain the architecture
- But I struggle to articulate **why it matters to the business**
- And I lack **usage metrics** / **impact stories**
    
### I need to prepare “deep slices” — not just high-level

Interviewers don’t want:

- “Takumi is complex”
- “It bundles best practices”
- “The system helps debugging”
    

They want:

- a specific bug I chased for 2 hours
- a confusing internal Takumi behavior and how I investigated
- a concrete incident where Insight cut diagnosis time
- a false alarm scenario and how I improved it

### I need to own the story even if the project impact is low

Resource Utilization was not widely used — that’s okay.  
But I still need to frame:

- what problem it _intended_ to solve
- how I designed it to be extensible
- what I’d do differently now
- what I learned about stakeholder alignment

---
## Action Items

### Prepare 3 concrete challenges with Takumi

- gRPC metadata propagation issues
- Gateway routing quirks
- Unexpected shutdown behavior (terminator)
- Zest config hot reload edge cases
- Tracing context not propagating

###  Prepare 2 real “business-impact” narratives for Insight

- Caught abnormal latency in SG ↔ JP route
- Helped isolate a forwarding bottleneck
- Prevented a debugging spiral by identifying wrong hop
    
### Prepare safe, realistic cost examples for Resource Utilization

- “In typical BU X, an idle t3.large costs XX/month; identifying 20 such nodes saves ~XX/month.”
- “In environments with hundreds of EC2s, even small optimizations compound.”

### Prepare a polished “redo the project” answer

For both Insight & Utilization:

- modularity
- configuration
- reliability
- scaling
- stakeholder feedback loop

---
## Questions I ask

- Given my background in infra + backend, which parts of the promotion system do you think I can contribute to most immediately?

(I tend to zone out during this section; need to practice active listening)