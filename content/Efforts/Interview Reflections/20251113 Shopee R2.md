---
title:
draft: true
tags:
  - real-interview
date: 2025-11-13
---
## Meta

- Company: Shopee
- Role: [Backend Engineer](https://careers.shopee.sg/job-detail/J02018173/1)
- Team: Marketplace, Buyer Team
- Interviewer: Yang Ming (Engineering Manager)
- Focus: System Design

---
## Problem Statement

> [!info]- Original Problem Statement
> 
> Design a system for a delayed message queue. The system should allow:
> 
> - Schedule messages: Users can call a schedule API to send a message with a delay (from 0 seconds to 10 days). The message content and the desired delivery time should be specified in the request.
>     
> - Cancel messages: Users can call a cancel API to cancel a scheduled message delivery before it's sent.
>     
> - Delivering messages: The system must deliver messages at their scheduled timestamp by calling a provided 3rd party API. If failed, need to retry until x times.
> 
> 
> Your Task: Design this delayed message queue system. Consider the following aspects:
> 
> - Data structures: What data structures will you use to store messages and their associated information?
>     
> - Scheduling mechanism: How will you ensure messages are delivered at their scheduled times?
>     
> - Consistency: How will you ensure message cancellation requests are processed before the message is delivered?
>     
> - Scalability: How can you scale the system to handle a large volume of messages?
>     
> - Error handling: How will the system handle errors during message scheduling, cancellation, or delivery?

Design a system for a delayed message queue: 

- Be able to **schedule** a message with a delay (0s–10 days).
- Be able to **cancel** a scheduled message.
- Deliver the message **exactly at the scheduled timestamp** by calling a 3rd-party API.
- Handle retries.
- Think about data structure, scheduling logic, consistency, scalability.

---
## What I did

### Tried to use templates (but didn’t help)

- I asked the usual:
    - Functional requirements
    - Non-functional requirements
    - QPS...
        
- But I **did not know how to use the info** meaningfully → felt mechanical.

### High-level design

- Proposed:

```
Client → API → LB → Queue Service → (cronjob) → 3rd-party API
                       ↓
                      Cache
                       ↓
                       DB
```
    
- But the design was **messy**:
    - unclear scheduling component
    - unclear ownership of delays
    - unclear message lifecycle
    
### API design struggle

- Proposed: 

```
POST v1/send_message
{
    "content": xxx
    "delivery_time": xxx (unix timestamp)
}

response
{
    "success": true / false
    "message_id": xxx
}

POST v1/cancel_message?message_id={}
```

- Struggled even on basic REST API format
    - exact request/response fields
    - how to include info in body
        
> [!warning] Weakness Exposed: REST API design

### Data structure confusion

- Forgot Redis **sorted set / ZSET**, even after hint
    
- Tried to describe a weird “map inside a map” structure that doesn’t solve the problem
    
- Brain was completely blank — I didn’t recall the right DS

> [!warning] Weakness Exposed: Redis Data Structure & Applications

### Scheduling logic failed

- Proposed: 

```
current_ts  = initial_ts
    for {
        # fetch message scheduled_time = current_ts
        messages = get_current_msgs(current_ts)
        for message in mesages:
            go call_third_party(message, done)
        current_ts += 1
    }
```

- Initially suggested an infinite loop:
    `current_ts += 1 each second   fetch messages for that timestamp   send them`  
    
- Interviewer pointed out:
    - if processing takes > 1 second → timestamps drift → messages delayed or skipped
        
- My “fixes” (timestamp for-loop, batch blocking) were still:
    - single-threaded
    - not scalable
    - not safe
    - not time-accurate
        
- Tried to mention goroutines → but couldn’t structure concurrency properly.
    
- Hint: `WaitGroup` → but I couldn’t integrate it

- Poor pseudocode: mixing up Python & Go

> [!warning] Weakness Exposed
> - Concurrency in action (especially in Go)
> - System Design pseudocode

### Consistency issues — no solid answer

- How to avoid sending **canceled** messages?
- How to sync DB + cache?
- How to handle race conditions?
- Gave hand-wavy answers and didn’t convince anyone.

### Quota / rate limiting

- Question: What if sending too many messages hits 3rd-party API quota?
        
- My answer (“negotiate quota”) was obviously useless.
    
- Correct directions: 
    - rate limiting
    - throttling
    - backpressure
    - batching
    - circuit breaker

---
## Root Causes

### Lack of domain familiarity

- Haven't studied delayed queues seriously
- No building blocks to reason with

### Template dependency

- Tried to use the standard “ask requirements → propose architecture” template 
- But templates don’t work when understanding is shallow

### Weakness in concurrency fundamentals

- Used Go, but didn't choose the correct concurrency primitive
- Should've used worker pool instead of just spawning goroutines

> [!info]- Why Worker Pool instead of Goroutines in this case
> 
> Problem with gorotinue:
> - 1 goroutine per message → **unbounded** memory growth 
> - no central control → chaos
> - harder to coordinate retries, timeouts, cancellations
> 
> Worker pool
> - a fixed number of workers (goroutines)
> - all waiting for tasks from a **shared job queue**
> - workers process tasks concurrently
> 
> > resulting in: bounded concurrency, backpressure, predictable throughput

### Redis data structure knowledge gaps

- Forgot the use of Sorted set (Zset)
- Used inappropriate data structure (Hset) instead 

> [!info]- Scheduling Logic & Redis structure
> 
> In my initial design, I used a `current_ts++` loop and tried to finish all messages for that timestamp before moving to the next. 
> 
> The problem with that approach is it couples time progression with processing speed — if one timestamp has a huge backlog, I basically freeze time and never catch up, and I also don’t handle late-inserted messages well.
> 
> A more robust design is to treat time as continuous and always query “all messages with `deliver_at <= now`”. That means:
> 
> - I won’t miss messages that arrive slightly late.
>     
> - Backlogs naturally show up as more messages “due” than workers can handle.
>     
> - Time moves forward independently of whether I’m fully caught up.
>     
> 
> To make this efficient, I separate roles:
> 
> - Redis **ZSET** acts as the schedule index (sorted by `deliver_at`).
>     
> - A **scheduler** periodically moves due messages into a **ready queue**.
>     
> - Workers only consume from the ready queue, so they don’t need to hit the heavy ZSET frequently, and I can control concurrency / throughput cleanly.

### No schema for scheduling

Lack a scheduling-system mental model: 
- priority queues
- min-heaps
- sorted sets
- time-wheel
- message buckets
- delay buckets + ready queue
    
---
## Areas to improve

### Domain knowledge

- Study how delayed queues are built:
    - Redis ZSET delayed queue
    - Min-heap / priority queue
    - Time-wheel algorithm
    
### Concurrency

- Understand:
    - worker pool
    - rate limiter
    - WaitGroup
    - fan-out / fan-in patterns
    - backpressure mechanisms

### API design

- Practice defining clean, realistic REST endpoints:
    - idempotency
    - response schema
    - error codes
    - message lifecycle

### Consistency

- Learn:
    - atomic updates
    - message state machine
    - cache invalidation
    - locking and optimistic concurrency
    - dedupe logic
    
### System design foundations

- Queues
- schedulers
- retries & dead-letter queues
- throughput vs latency
- scaling delivery workers


> [!info] See also
> - [[Design a Delayed Message Queue]] — full design breakdown, tradeoffs, and final architecture
> - [[Why This Delayed Queue Question Hit Differently]] — analysis of why this problem belongs to the “infra/system runtime” class of SD questions


