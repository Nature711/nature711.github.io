---
title:
draft: true
tags:
  - "#real-interview"
date: 2025-11-21
---
## Meta

- Company: Shopee
- Role: Backend Engineer
- Team: Marketplace, Promotion Team
- Interviewer: Naseer Khan
- Focus: Light Coding + System Design

---
## Overview 

- Coding: short sanity check (palindrome, Daily Temperatures).
    
- System design: majority of discussion; focused on **voucher quota system under high QPS**.
    
- Tone: collaborative, open, positive; design felt like co-thinking with teammate.
    
---

## System Design

### Initial Architecture (DB-Centric Correctness Approach)

**Architecture Proposal**

- API Gateway → Voucher Service → Database
- Two DB tables:
    - `voucher` → voucher metadata + current claimed count
    - `voucher_limit` → voucher ID → limit
        
**Claim Workflow**

1. Query `voucher` to get current count.
2. Query `voucher_limit` to get quota.
3. Compare.
4. If allowed → increment count.
5. All inside a **DB transaction** for atomicity.
    
**Strength**

- Strict correctness.
- No oversell.
- Easy to implement.
    
**Weaknesses**

- DB becomes a **hotspot**.
- High QPS, concurrent attempts → row lock contention.
- No ability to scale horizontally.
- Latency too high for campaign events.

### First Optimization: Denormalization

**Change**

- Merge `limit` and `count` into one row in one table.

**Effect**

- Reduce DB round trips (1 query instead of 2).
- Reduce locking to a single row.

**Limitations**

- Still fundamentally DB-bound.
- Row-level lock → throughput bottleneck.
- Campaign bursts (thousands per second) cannot be handled.

### Second Optimization: Redis Cache

**Design Attempt**

- Store `{limit, count}` for voucher in Redis:
    - Key: `voucher:{id}`
    - Value: hash `{limit, count}`
- Query/compare/update Redis for each claim.
- After that, write updated count to DB “for persistence.”

**Benefits**

- Redis is in-memory → fast.
- Removes DB from hot path.
- Can achieve significantly higher QPS.
    
**Issues Raised by Interviewer**

- If Redis is used as a read-write cache, and **every** update triggers a DB write:
    - DB load is still O(N) with number of requests.
    - DB becomes bottleneck again.
- Missing atomicity: race conditions without Lua scripts.
- Using Redis as “just a cache” misses the point; needs to be **the authority** for quota.

### Redis Scaling (My Third Optimization)

**Ideas Proposed**

- Redis Cluster with sharding by voucher ID.
- Multiple Redis nodes to split load.
- Replicas for high availability.
- Horizontal scaling to avoid overload.

**Correctness Considerations Raised**

- If Redis crashes → quota state lost → oversell possible.
- Redis needs to be durable or backed by a fallback mechanism.
- Still insisted *DB must remain the source of truth*.

**Shortfall**

- Even with scaling, Redis cluster cannot solve:
    - durability
    - high-frequency DB writes
    - synchronization between Redis & DB

### Follow-up Idea: Temporarily Disable System if Redis Down

**Fallback Approach**

- Redis becomes unavailable → block voucher claiming.
- Wait for Redis to recover.
- Avoid oversell by halting issuance.
    
**Strength**

- *Fail-closed* design is actually correct in industry systems.
- Prevents incorrect states.
    
**Limitation**

- Still lacks ***durability***:
    - Redis crash → count lost
    - DB does not have real-time count

> [!check]- Corrected Understanding: Redis Durability & Source-of-Truth Design
> 
> - Redis **does support persistence** (RDB snapshots, AOF logging, replication), but these mechanisms are **best-effort**, not strictly durable under all failure modes.
>     
> - Redis persistence can **lose recent writes** during crashes, failover, or `fsync` delays, especially under high QPS.
> 	 - e.g., asynchronous replication: may drop the latest writes if failover happens mid-sync
> 	 - AOF with `fsync = everysec`: can lose up to 1 second of writes under crash
> 	 - AOF with `fsync = always`: better durability but hurts throughput 
> 	 
> - Therefore, Redis **cannot be the sole source of truth** for high-stakes quota systems (e.g., vouchers, flash sale inventory).
>     
> - Correct design separates responsibilities:
>     
>     - **Redis = real-time truth** (atomic ops, high QPS).
>         
>     - **Kafka = durable truth** (WAL, ensures no claim is lost; replayable).
>         
>     - **Database = long-term, eventual truth** (final persisted state).
>         
> - If Redis fails → **fail closed** (temporarily block claiming) and **rebuild Redis state from Kafka/DB**, not rely on Redis persistence.
>     
> - Overall: **Redis for speed + Kafka for durability + DB for long-term consistency** is the correct mental model for large-scale promotion systems. 
---

> [!info]- Interview-ready explanation
> Redis does have persistence (RDB/AOF) and HA, but its durability is still best-effort under failover and fsync tradeoffs. At high QPS, setting strict fsync or sync replication hurts latency and throughput, and there’s still a small risk of losing the latest writes.  
> So we rely on Redis for real-time atomic quota control, and Kafka/DB as the durable ledger, with reconciliation to recover Redis if needed.

---
## Industry Pattern (Correct Architecture for Promo Systems)

### Essential Principles

- Never *oversell*
- Use *in-memory* systems (Redis) for real-time concurrency control
- *Durable event logs* (Kafka) for correctness
- *Asynchronous* DB writes for scalability
- Periodic *reconciliation* for state consistency

### Correct Hot-Path (Write Path)

 **1. Redis (Atomic Lua Gatekeeper)**

- Maintains real-time quota
- Enforces:
    - global limit
    - per-user limit
    - strict atomicity
- Accepts extremely high QPS
    
> Redis is the _only authority_ for remaining quota.

**2. Kafka (Durable Write-Ahead Log)**

After Redis approves a claim:
- Publish event: `VoucherClaimed(user_id, voucher_id, ts)`
- Kafka acts as:
    - ***durable*** buffer
    - event log
    - reliable message queue

If Redis crashes:
- Kafka still has the events.
- DB can be rebuilt.
- Redis can be *rehydrated* from Kafka/DB.

**3. Asynchronous DB Writer**

A consumer reads Kafka events and updates the DB:
- Insert into `user_voucher`
- Record claim history
- Batch writes & reduce DB load drastically
- DB becomes **eventually consistent**, not real-time
    
> Thus DB is **long-term persistent truth**, not real-time allocator.

**4. Reconciliation Job**

Periodically compare:
- Redis quota
- Kafka event count
- DB record count

If mismatch:
- recompute remaining quota
- reinitialize Redis

 > This makes the system *self-healing*.

---
## Questions to Interviewer 

### Double Eleven Incident

- Described my real user experience: voucher showed “claimed” then “fully redeemed.”
- Asked how this happens under concurrency.
- Led to discussion about:
    - consistency
    - race conditions
    - cache vs DB mismatch
    - real-time quota enforcement
        
### Challenges Faced by Promo Team

- Traffic increases every year.
- Product requests evolve (e.g. showing final discounted price on product page).
- Even one UI feature → huge additional query load → backend complexity increases.
	- showed understanding of product-to-backend propagation effects.

---
## Overall Reflection

### Behavioral Strengths

- Collaborative mindset: treated interviewer like a partner doing joint system design.
- Calm, clarifying questions.
- Willingness to rethink design and explore trade-offs.
- Not defensive — open to interviewer’s hints.

### Improvement Areas

#### Over-focus on DB consistency

- Need to shift mindset:
    - DB = long-term truth
    - Redis = real-time truth
    - Kafka = durable truth
    
#### Did not elevate the design to event-driven architecture

- Should introduce Kafka earlier
- Should show comfort with async patterns

#### Lack of high-QPS patterns

Add these into muscle memory:
- Hot-key sharding
- Redis Lua scripts
- Local pre-allocation tokens
- Fail-closed behavior
- Region-level quota partitioning

#### Not enough attention to tradeoffs

- Availability vs correctness
- Under-issue vs oversell
- Latency vs freshness
- Cache warm-up strategies
- Cold-start issues

