---
title:
draft: true
tags:
  - "#real-interview"
date: 2025-11-17
---
## Meta

- Company: Manus AI
- Role: DevOps Engineer (SRE)
- Focus: Project Experience, Infra / SRE practices deep dive

---
## Insight Project 

### What I was asked

- How cross-region routing actually works 
	- Mediary, TGW, VPC peering, private link, etc.
    
- Realistic latency numbers
	- e.g., SG ↔ US East
    
- How often we should run probes and what trade-offs exist
	- too frequent — may overload metrics storage
	- too slow — may miss informative data

- Actual business value / real operational scenario
    
### How I responded

Only described the high-level idea:
- SG and US regions don’t communicate directly
- Forward requests through Mediary with some routing table
- Latency might be “around 100 ms” (guessing)
- Probe frequency “maybe 1 minute” (also guessing)
- Said the project is still in development so we haven’t finalized decisions

Repeated the value point: “We want hop-level breakdown to help locate issues.”

### What was correct

- Mediary _does_ forward cross-region requests
- Hop-level latency _is_ useful for debugging
- The system _should_ help identify which segment is slow

### What was weak

- Couldn’t explain **how** cross-region routing actually works  
    (TGW / PrivateLink / VPC peering / NAT / egress routing)
- Didn’t know real latency numbers
- Didn’t discuss **public vs private path**
- Couldn’t justify probe frequency using SRE principles:
    - sampling cost
    - Prometheus cardinality
    - risk of missing short spikes
- Value explanation sounded abstract without a concrete example

### How I should improve

- Learn **AWS networking fundamentals**: TGW, route tables, IGW, NAT, VPC peering
- Memorize realistic regional latency numbers
- Understand SRE concepts: sampling intervals, cost, cardinality, alerting
- Prepare a **real scenario** for Insight (“e.g., TGW routing degradation causing a 40ms jump at hop 3”)

---
## Resource Utilization Reporting Report

### What I was asked

- How I collected CPU/memory/disk data
- How exactly I computed utilization (rate? average?)
- Problems with using daily averages
	- What if there are spikes?
	- Would the system mislead business teams?

### How I responded

Explained the pipeline:
- YACE → Prometheus → my Python ETL → PolarDB
- Compute average over one day using PromQL rate/avg
- Mentioned that I also output max metrics
- Said business teams would “double check raw data” before making decisions

### What was correct

- Collection Pipeline itself
- Rate/avg are legitimate PromQL operators
- Exposing avg + max is a normal practice
    
### What was weak

- Daily average _can_ hide spikes; no strong justification
- Explanation about “business checking raw data” was improvised
- Didn’t discuss best practices like:
    - p95 / p99
    - smoothing windows
    - static vs dynamic thresholds
    - anomaly detection
- Couldn’t explain how SRE teams normally judge underutilization

### How I should improve

- Learn standard capacity-planning metrics:
    - avg vs p95 vs p99
    - daily vs hourly aggregation
    - sustained peak definition
- Prepare examples: “Peak CPU reached 85% for 30 minutes each day → cannot downsize.”
- Clarify the real use case and value of the system

---
## Cloud Cost Management

### What I was asked

- How raw AWS billing data is enriched
- How to allocate cost for **shared resources** like Kubernetes node pools
- How Reserved Instances calculation works

### How I responded

- Said I handled mapping raw bills to BU tags
- Talked about adding custom fields before inserting to DB
- For shared resources, I admitted I didn’t know and guessed there was “some logic”
- Mentioned k8s cost is done by “someone else”
- Tried to explain the RI logic but wasn't clear
    
### What was correct

- Nothing :(
    
### What was weak

- Had no explanation of how k8s cost allocation works 
- Couldn’t describe:
    - node pool cost
    - container CPU/Memory usage
    - amortization of cluster overhead
- Lacked understanding of multi-tenant cost attribution frameworks
    
### How to improve

- Learn k8s cost allocation basics
- Study the Kubecost model:
    - idle cost
    - shared cost
    - workload-attributed cost
- Prepare a simple example:  
    “Node = $100/day, Pod A uses 20% CPU so it gets $20/day.”

---
## Ops Platform

### What I was asked

- How deployments should work
- Difference between VM deployment and container deployment
- Basic Kubernetes scheduling logic
- What orchestration components are involved
- How to design one

### How I responded

Described based on my limited exposure:

- VM deployments → Jenkins → Ansible → remote operations
- Containers → a layer that wraps k8s API
- Scheduling “probably uses k8s logic behind the scenes”
- Admitted I wasn’t entirely sure

### What was correct

- Jenkins → Ansible pipeline is correct
- An Ops platform _does_ wrap k8s concepts
- It _is_ an abstraction over deployment

### What was weak

- Could not describe core concepts:
    - control plane vs data plane
    - Deployment → ReplicaSet → Pods
    - Scheduler decision process (binpacking, resource requests)
    - Rolling update
    - Health checks / liveness / readiness
        
- Could not discuss:
    - cluster autoscaling
    - node pools
    - image registry
    - RBAC

### How to improve

- Study a clean mental model of Kubernetes:
    - pods, nodes, deployments
    - scheduling
    - service mesh
    - CRD & controller pattern
- Learn how internal platforms abstract these

---
## AWS Architecture Design & Cloud Networking

### What I was asked

- “How would you deploy a WeChat backend on AWS?”
- Network-level details: VPC, routing, SG, ALB, NAT
- Security model
- Cloud-native design
    
### How I responded

Gave a high-level architecture:

- CDN
- ALB
- ASG (EC2 auto-scaling group)
- RDS
- Redis
- IAM
- CloudWatch

When asked deeper questions:
- Couldn’t detail how traffic moves inside AWS
- Couldn’t articulate Cloud Security layers
- Got lost in network-level details
    
### What was correct

- The high-level architecture was fine
- Using CDN + ALB + ASG is a standard pattern
- RDS + ElastiCache is correct
- IAM / CloudWatch are correct

### What was weak

- Don’t understand VPC inside-out
- Can’t explain routing (IGW, NAT, TGW, route tables)
- Don’t know how SG differs from NACL
- Don’t know how multi-AZ / multi-region failover works
- Couldn’t reason about trade-offs

### How to improve

- Build a **VPC mental model** (super important)
- Study AWS networking diagrams
- Learn how to explain cloud security
- Practice describing architectures verbally
    
---
## Final Reflection

- Have some **broad exposure** but lack **deep, structured understanding** of core infra topics
- Often described what happens, but couldn’t explain _how_ or _why_
- No answer when pushed for: mechanisms, numbers, trade-offs, etc.

> Goal: to turn scattered experience into a solid infrastructure foundation



